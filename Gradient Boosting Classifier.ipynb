{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56a6b1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "859506c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn import datasets\n",
    "\n",
    "from sklearn.model_selection import cross_val_score,train_test_split,GridSearchCV\n",
    "from sklearn.pipeline import Pipeline,make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7f2ec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier,GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3204a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "bike = datasets.load_iris()\n",
    "X, y = bike.data, bike.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e441d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(r'C:\\Users\\kelvin\\Downloads\\Social_Network_Ads.csv')\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size = 0.3,random_state=42)\n",
    "#misssing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7918a7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = 0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9075b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = GradientBoostingRegressor(n_estimators = 200, max_depth = 1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fe14de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(max_depth=1, n_estimators=200, random_state=42)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(max_depth=1, n_estimators=200, random_state=42)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "769dbe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = gbr.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d0da823",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rmse = MSE(test_y, pred) ** (1 / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cab5285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE test set: 0.10\n",
      "RMSE test set: 0.10\n"
     ]
    }
   ],
   "source": [
    "print('RMSE test set: {:.2f}'.format(test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0fa97d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "0  15624510    Male   19            19000          0\n",
       "1  15810944    Male   35            20000          0\n",
       "2  15668575  Female   26            43000          0\n",
       "3  15603246  Female   27            57000          0\n",
       "4  15804002    Male   19            76000          0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15624510</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>19000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15810944</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15668575</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>43000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15603246</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>57000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15804002</td>\n",
       "      <td>Male</td>\n",
       "      <td>19</td>\n",
       "      <td>76000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "0  15624510    Male   19            19000          0\n",
       "1  15810944    Male   35            20000          0\n",
       "2  15668575  Female   26            43000          0\n",
       "3  15603246  Female   27            57000          0\n",
       "4  15804002    Male   19            76000          0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(r'C:\\Users\\kelvin\\Downloads\\Social_Network_Ads.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a31be61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (400, 2)\n",
      "y (400,)\n",
      "Accuracy: 0.9555555555555556\n",
      "X (400, 2)\n",
      "y (400,)\n",
      "Accuracy: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size = 0.3,random_state=42)\n",
    "X = dataset.iloc[:, [2, 3]].values\n",
    "y = dataset.iloc[:, 4].values\n",
    "print(\"X\",X.shape)\n",
    "print(\"y\",y.shape)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier1 = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "classifier1.fit(X_train, y_train)\n",
    "\n",
    "y_pred1 = classifier1.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4c6ad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr1 = GradientBoostingClassifier(n_estimators = 200, max_depth = 1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a37ec62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=1, n_estimators=200, random_state=42)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=1, n_estimators=200, random_state=42)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a89fc4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = gbr1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "feefdce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21ce8e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  sklearn.ensemble import RandomForestClassifier\n",
    "regressor = RandomForestClassifier(n_estimators=100,random_state=42)\n",
    "regressor.fit(X_train,y_train)\n",
    "\n",
    "y_preds = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "716a58ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------Gradient Boosting Classifier-------------\n",
      "accuracy_score: 1.0\n",
      "confusion_matrix: [[19  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0 13]]\n",
      "classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "-----------------Random Forest-------------\n",
      "accuracy_score: 1.0\n",
      "confusion_matrix: [[19  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0 13]]\n",
      "classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "-----------------Decision Tree Classifier-------------\n",
      "n\u0007ccuracy_score: 0.9555555555555556\n",
      "n\\confusion_matrix: [[19  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  2 11]]\n",
      "n\\classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       0.87      1.00      0.93        13\n",
      "           2       1.00      0.85      0.92        13\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.96      0.95      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n",
      "-----------------Gradient Boosting Classifier-------------\n",
      "accuracy_score: 1.0\n",
      "confusion_matrix: [[19  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0 13]]\n",
      "classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "-----------------Random Forest-------------\n",
      "accuracy_score: 1.0\n",
      "confusion_matrix: [[19  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0 13]]\n",
      "classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n",
      "-----------------Decision Tree Classifier-------------\n",
      "n\u0007ccuracy_score: 0.9555555555555556\n",
      "n\\confusion_matrix: [[19  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  2 11]]\n",
      "n\\classification_report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       0.87      1.00      0.93        13\n",
      "           2       1.00      0.85      0.92        13\n",
      "\n",
      "    accuracy                           0.96        45\n",
      "   macro avg       0.96      0.95      0.95        45\n",
      "weighted avg       0.96      0.96      0.96        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('-----------------Gradient Boosting Classifier-------------')\n",
    "print('accuracy_score:', accuracy_score(y_test,pred_y))\n",
    "print('confusion_matrix:',confusion_matrix(y_test,pred_y))\n",
    "print('classification_report:',classification_report(y_test,pred_y))\n",
    "print('-----------------Random Forest-------------')\n",
    "print('accuracy_score:',accuracy_score(y_test,y_preds))\n",
    "print('confusion_matrix:',confusion_matrix(y_test,y_preds))\n",
    "print('classification_report:',classification_report(y_test,y_preds))\n",
    "print('-----------------Decision Tree Classifier-------------')\n",
    "print('n\\accuracy_score:',accuracy_score(y_test,y_pred1))\n",
    "print('n\\confusion_matrix:',confusion_matrix(y_test,y_pred1))\n",
    "print('n\\classification_report:',classification_report(y_test,y_pred1))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d9a25f68",
   "metadata": {},
   "source": [
    "loss = ['log_loss','deviance','exponential']\n",
    "learning_rate = [0.001,0.1,0.5]\n",
    "n_estimators = [100,150,200]\n",
    "subsample =[0.0,1.0]\n",
    "criterion =['friedman_mse','squared_error'],\n",
    "'min_samples_split'=[0.0,1.0]\n",
    "min_samples_leaf = [0.0,1.0]\n",
    "max_features_ =['auto','sqrt','log2','int','float']\n",
    "random_state = int\n",
    "max_depth = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3df6c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \n",
    "    'loss' : ['log_loss','deviance','exponential'],\n",
    "    'learning_rate' : [0.001,0.1,0.5,0.7,0.9],\n",
    "    'n_estimators' : [100,110,120] ,\n",
    "    'subsample' : [0.1,0.2,0.3,0.6,0.9],\n",
    "    'criterion' : ['friedman_mse','squared_error'],\n",
    "    'max_features' :['auto','sqrt','log2','int','float'],\n",
    "    'max_depth' : [100,110,120]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7285cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "27000 fits failed out of a total of 33750.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "11250 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 282, in _check_params\n",
      "    raise ValueError(\"Loss '{0:s}' not supported. \".format(self.loss))\n",
      "ValueError: Loss 'log_loss' not supported. \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2250 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 343, in _check_params\n",
      "    raise ValueError(\n",
      "ValueError: Invalid value for max_features: 'int'. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2250 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 343, in _check_params\n",
      "    raise ValueError(\n",
      "ValueError: Invalid value for max_features: 'float'. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "11250 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 310, in _check_params\n",
      "    self.loss_ = loss_class(self.n_classes_)\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb_losses.py\", line 890, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: ExponentialLoss requires 2 classes; got 3 class(es)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n",
      "D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "27000 fits failed out of a total of 33750.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "11250 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 282, in _check_params\n",
      "    raise ValueError(\"Loss '{0:s}' not supported. \".format(self.loss))\n",
      "ValueError: Loss 'log_loss' not supported. \n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2250 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 343, in _check_params\n",
      "    raise ValueError(\n",
      "ValueError: Invalid value for max_features: 'int'. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2250 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 343, in _check_params\n",
      "    raise ValueError(\n",
      "ValueError: Invalid value for max_features: 'float'. Allowed string values are 'auto', 'sqrt' or 'log2'.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "11250 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 310, in _check_params\n",
      "    self.loss_ = loss_class(self.n_classes_)\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_gb_losses.py\", line 890, in __init__\n",
      "    raise ValueError(\n",
      "ValueError: ExponentialLoss requires 2 classes; got 3 class(es)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GradientBoostingClassifier(random_state=42),\n",
       "             param_grid={'criterion': ['friedman_mse', 'squared_error'],\n",
       "                         'learning_rate': [0.001, 0.1, 0.5, 0.7, 0.9],\n",
       "                         'loss': ['log_loss', 'deviance', 'exponential'],\n",
       "                         'max_depth': [100, 110, 120],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2', 'int',\n",
       "                                          'float'],\n",
       "                         'n_estimators': [100, 110, 120],\n",
       "                         'subsample': [0.1, 0.2, 0.3, 0.6, 0.9]})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=GradientBoostingClassifier(random_state=42),\n",
       "             param_grid={'criterion': ['friedman_mse', 'squared_error'],\n",
       "                         'learning_rate': [0.001, 0.1, 0.5, 0.7, 0.9],\n",
       "                         'loss': ['log_loss', 'deviance', 'exponential'],\n",
       "                         'max_depth': [100, 110, 120],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2', 'int',\n",
       "                                          'float'],\n",
       "                         'n_estimators': [100, 110, 120],\n",
       "                         'subsample': [0.1, 0.2, 0.3, 0.6, 0.9]})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr = GradientBoostingClassifier(random_state = 42)\n",
    "md = GridSearchCV(gbr,params,cv=5)\n",
    "md.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49bd8480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'friedman_mse',\n",
       " 'learning_rate': 0.5,\n",
       " 'loss': 'deviance',\n",
       " 'max_depth': 100,\n",
       " 'max_features': 'sqrt',\n",
       " 'n_estimators': 100,\n",
       " 'subsample': 0.6}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'friedman_mse',\n",
       " 'learning_rate': 0.5,\n",
       " 'loss': 'deviance',\n",
       " 'max_depth': 100,\n",
       " 'max_features': 'sqrt',\n",
       " 'n_estimators': 100,\n",
       " 'subsample': 0.6}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64b6d6fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9523809523809523"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.9523809523809523"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
