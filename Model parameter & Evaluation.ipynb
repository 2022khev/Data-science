{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01b50b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.pipeline import make_pipeline,Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X,y = make_classification(n_samples = 1000,n_classes = 2,n_features = 10,n_redundant=0,random_state=42)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad833ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': {'logisticregression__C': [0.1, 1, 10]},\n",
       " 'l2': {'logisticregression__C': [0.1, 1, 10]},\n",
       " 'rf': {'randomforestclassifier__n_estimators': [100, 200],\n",
       "  'randomforestclassifier__max_features': ['auto', 0.3, 0.6],\n",
       "  'randomforestclassifier__criterion': ['entropy', 'gini']},\n",
       " 'gb': {'gradientboostingclassifier__n_estimators': [100, 200],\n",
       "  'gradientboostingclassifier__learning_rate': [0.05, 0.1, 0.2],\n",
       "  'gradientboostingclassifier__max_depth': [1, 3, 5]}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1       :pipeline\n",
    "\n",
    "pipeline = {\n",
    "      'l1':make_pipeline(StandardScaler(),  LogisticRegression(penalty='l1',random_state=42, solver = 'liblinear')),\n",
    "      'l2':make_pipeline(StandardScaler(),  LogisticRegression(penalty='l2',random_state=42, solver = 'liblinear')),\n",
    "      'rf': make_pipeline(StandardScaler(), RandomForestClassifier(random_state=1)),\n",
    "      'gb': make_pipeline(StandardScaler(), GradientBoostingClassifier(random_state=1))\n",
    "    \n",
    "}\n",
    "pipeline\n",
    "\n",
    "# Step  parameters seperately\n",
    "l1_hyperparameters = {\n",
    "        'logisticregression__C':[0.1,1,10]\n",
    "}\n",
    "\n",
    "l2_hyperparameters = {\n",
    "        'logisticregression__C':[0.1,1,10]\n",
    "}\n",
    "\n",
    "rf_hyperparameters = {\n",
    "    'randomforestclassifier__n_estimators' : [100, 200],\n",
    "    'randomforestclassifier__max_features' : ['auto', 0.3, 0.6],\n",
    "     'randomforestclassifier__criterion' : ['entropy','gini']\n",
    "    \n",
    "}\n",
    "\n",
    "gb_hyperparameters = {\n",
    "    'gradientboostingclassifier__n_estimators' : [100, 200],\n",
    "    'gradientboostingclassifier__learning_rate' : [0.05, 0.1, 0.2], #0.05,0.1,0.2\n",
    "    'gradientboostingclassifier__max_depth' : [1, 3, 5]\n",
    "}\n",
    "\n",
    "#Step 3 Join parameters\n",
    "hyperparameters = {\n",
    "'l1' : l1_hyperparameters,\n",
    "'l2' : l2_hyperparameters ,\n",
    "'rf' : rf_hyperparameters,\n",
    "'gb' : gb_hyperparameters\n",
    "}\n",
    "hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27530d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4 merge pipeline & parameters\n",
    " #store values in models dictionary\n",
    "models = {}\n",
    "for key in pipeline.keys() :\n",
    "    models[key] = GridSearchCV(pipeline[key], hyperparameters[key], cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "925ec084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1  is trained and tuned.\n",
      "l2  is trained and tuned.\n",
      "rf  is trained and tuned.\n",
      "gb  is trained and tuned.\n"
     ]
    }
   ],
   "source": [
    "#Step 5 Train the model\n",
    "for key in models.keys():\n",
    "    models[key].fit(X_train, y_train)\n",
    "    print(key, ' is trained and tuned.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5111802",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6819207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------Logistic Regression 1------------------------------\n",
      "Confusion Matrix: \n",
      " [[125  17]\n",
      " [ 20 138]]\n",
      "\n",
      "Accuracy_score: \n",
      " 0.8766666666666667\n",
      "\n",
      "classification_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87       142\n",
      "           1       0.89      0.87      0.88       158\n",
      "\n",
      "    accuracy                           0.88       300\n",
      "   macro avg       0.88      0.88      0.88       300\n",
      "weighted avg       0.88      0.88      0.88       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "print('\\n-----------------Logistic Regression 1------------------------------')\n",
    "print('Confusion Matrix: \\n',confusion_matrix(y_test,models['l1'].predict(X_test)))\n",
    "print('\\nAccuracy_score: \\n',accuracy_score(y_test,models['l1'].predict(X_test)))\n",
    "print('\\nclassification_report\\n',classification_report(y_test,models['l1'].predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80e9bbae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------Logistic Regression 2------------------------------\n",
      "Confusion Matrix: \n",
      " [[126  16]\n",
      " [ 17 141]]\n",
      "\n",
      "Accuracy_score: \n",
      " 0.89\n",
      "\n",
      "classification_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88       142\n",
      "           1       0.90      0.89      0.90       158\n",
      "\n",
      "    accuracy                           0.89       300\n",
      "   macro avg       0.89      0.89      0.89       300\n",
      "weighted avg       0.89      0.89      0.89       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\n-----------------Logistic Regression 2------------------------------')\n",
    "print('Confusion Matrix: \\n',confusion_matrix(y_test,models['l2'].predict(X_test)))\n",
    "print('\\nAccuracy_score: \\n',accuracy_score(y_test,models['l2'].predict(X_test)))\n",
    "print('\\nclassification_report\\n',classification_report(y_test,models['l2'].predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58be94c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------Random Forest Classifier------------------------------\n",
      "Confusion Matrix: \n",
      " [[136   6]\n",
      " [ 16 142]]\n",
      "\n",
      "Accuracy_score: \n",
      " 0.9266666666666666\n",
      "\n",
      "classification_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.93       142\n",
      "           1       0.96      0.90      0.93       158\n",
      "\n",
      "    accuracy                           0.93       300\n",
      "   macro avg       0.93      0.93      0.93       300\n",
      "weighted avg       0.93      0.93      0.93       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\n-----------------Random Forest Classifier------------------------------')\n",
    "print('Confusion Matrix: \\n',confusion_matrix(y_test,models['rf'].predict(X_test)))\n",
    "print('\\nAccuracy_score: \\n',accuracy_score(y_test,models['rf'].predict(X_test)))\n",
    "print('\\nclassification_report\\n',classification_report(y_test,models['rf'].predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28a4a960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-----------------Gradient Boosting Classifier------------------------------\n",
      "Confusion Matrix: \n",
      " [[133   9]\n",
      " [ 15 143]]\n",
      "\n",
      "Accuracy_score: \n",
      " 0.92\n",
      "\n",
      "classification_report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       142\n",
      "           1       0.94      0.91      0.92       158\n",
      "\n",
      "    accuracy                           0.92       300\n",
      "   macro avg       0.92      0.92      0.92       300\n",
      "weighted avg       0.92      0.92      0.92       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\n-----------------Gradient Boosting Classifier------------------------------')\n",
    "print('Confusion Matrix: \\n',confusion_matrix(y_test,models['gb'].predict(X_test)))\n",
    "print('\\nAccuracy_score: \\n',accuracy_score(y_test,models['gb'].predict(X_test)))\n",
    "print('\\nclassification_report\\n',classification_report(y_test,models['gb'].predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
