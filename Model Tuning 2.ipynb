{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a41405c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The crossvalidation of \n",
      " LogisticRegression() = [0.925  0.9    0.8875 0.925  0.9625]\n",
      "   and the accuracy score of LogisticRegression() is 92.0 %\n",
      "\n",
      " The crossvalidation of \n",
      " SVC() = [0.9125 0.8875 0.8875 0.9    0.9375]\n",
      "   and the accuracy score of SVC() is 90.0 %\n",
      "\n",
      " The crossvalidation of \n",
      " KNeighborsClassifier() = [0.8875 0.85   0.875  0.85   0.9125]\n",
      "   and the accuracy score of KNeighborsClassifier() is 88.0 %\n",
      "\n",
      " The crossvalidation of \n",
      " RandomForestClassifier() = [0.9375 0.925  0.925  0.9    0.975 ]\n",
      "   and the accuracy score of RandomForestClassifier() is 93.0 %\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "X,y = make_classification(n_samples = 400,n_classes = 2,n_features = 10,n_redundant=0,random_state=42)\n",
    "\n",
    "\n",
    "models = [LogisticRegression(),SVC(),KNeighborsClassifier(),RandomForestClassifier()]\n",
    "\n",
    "def ModelSelection():\n",
    "    for model in models:\n",
    "        cv_score = cross_val_score(model,X,y,cv=5)\n",
    "        mean_accuracy = sum(cv_score)/(len(cv_score))\n",
    "        mean_accuracy = round(sum(cv_score)/(len(cv_score)),2)*100\n",
    "        print('\\n The crossvalidation of \\n',model,'=',cv_score)\n",
    "        print('   and the accuracy score of',model,'is',mean_accuracy,'%')\n",
    "ModelSelection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81bab398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "601dd823",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples = 400, n_classes=2, n_features=10, n_redundant=0, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d900b225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25994259",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad864e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LogisticRegression(), SVC(), KNeighborsClassifier(), RandomForestClassifier()]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = [LogisticRegression(),SVC(),KNeighborsClassifier(),RandomForestClassifier()]\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f6e797a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Cross validation accuracy for the\n",
      " LogisticRegression()  is [0.925  0.9    0.8875 0.925  0.9625]\n",
      " and Accuracy score for the LogisticRegression() is 92.0 %\n",
      "\n",
      " Cross validation accuracy for the\n",
      " SVC()  is [0.9125 0.8875 0.8875 0.9    0.9375]\n",
      " and Accuracy score for the SVC() is 90.5 %\n",
      "\n",
      " Cross validation accuracy for the\n",
      " KNeighborsClassifier()  is [0.8875 0.85   0.875  0.85   0.9125]\n",
      " and Accuracy score for the KNeighborsClassifier() is 87.5 %\n",
      "\n",
      " Cross validation accuracy for the\n",
      " RandomForestClassifier()  is [0.9375 0.925  0.925  0.8875 0.975 ]\n",
      " and Accuracy score for the RandomForestClassifier() is 93.0 %\n"
     ]
    }
   ],
   "source": [
    "def compare_models_validation():\n",
    "    for model in models:\n",
    "        cv_score = cross_val_score(model,X,y,cv=5)\n",
    "        mean_accuracy = sum(cv_score)/len(cv_score)\n",
    "        mean_accuracy =  mean_accuracy * 100\n",
    "        mean_accuracy =  round(mean_accuracy,2)\n",
    "        print('\\n Cross validation accuracy for the\\n',model , ' is', cv_score)\n",
    "        print(' and Accuracy score for the',model , 'is', mean_accuracy,'%')\n",
    "compare_models_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08023bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37cf82c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = [LogisticRegression(max_iter=10000),SVC(),KNeighborsClassifier(),RandomForestClassifier(random_state=0)]\n",
    "\n",
    "\n",
    "model_hyperparameters = {\n",
    "    'log_reg_hyperparameters':{\n",
    "        'C':[1,5,10,20]\n",
    "    },\n",
    "    'svc_hyperparameters' :{\n",
    "        'kernel':['linear','poly','rbf','sigmoid'],\n",
    "        'C':[1,5,10,20]\n",
    "    },\n",
    "    \n",
    "    'KNN_hyperparameters':{\n",
    "        'n_neighbors':[3,5,10]\n",
    "    },\n",
    "\n",
    "    'random_forest_hyperparameters':{\n",
    "    'n_estimators':np.arange(10,210,10),\n",
    "    'criterion':['entropy','gini','log_loss'],\n",
    "    'max_features':np.arange(1,6,1)\n",
    "                                     }\n",
    "}\n",
    "\n",
    "\n",
    "# model_hyperparameters\n",
    "# type(model_hyperparameters)\n",
    "model_keys = list(model_hyperparameters.keys())  #stored model_hyperparaneters keys to model_keys\n",
    "# model_hyperparameters['KNN_hyperparameters']\n",
    "# print(model_keys )\n",
    "# model_hyperparameters[model_keys[1]]\n",
    "# model_keys[0]\n",
    "# model_hyperparameters[model_keys[1]]\n",
    "\n",
    "def ModelSelection(list_of_models,hyperparameters_dictionary):  #function that takes two arguments\n",
    "    result = []                                                 #stored result in a list        \n",
    "    i = 0                                                       #Iterating to all models in a list\n",
    "    for model in models_list:                                   #condition\n",
    "        key = model_keys[i]                                     #Equating key to all model_kes[i]     \n",
    "        params = hyperparameters_dictionary[key]                #Equating params to hyperparameters_dictionary[key]   \n",
    "        \n",
    "        i=i+1                                                   #Iterating to all columns\n",
    "\n",
    "        print(model)                                            #printing all\n",
    "        print(params)                                           #printing all\n",
    "        print('---------------------------------------------------------------------')\n",
    "        classifier = GridSearchCV( model,params,cv=5)\n",
    "        classifier.fit(X,y)\n",
    "        \n",
    "        result.append({\n",
    "            'model_used' : model,\n",
    "            'highest_score':classifier.best_score_,\n",
    "             'best hyperameters' : classifier.best_params_\n",
    "            \n",
    "        })\n",
    "        result_dataframe = pd.DataFrame(result,columns =[ 'model_used', 'highest_score','best hyperameters'])\n",
    "#         return result_dataframe\n",
    "    return  result_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df09ffc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelSelection(list_a, hyper_a):\n",
    "    \n",
    "    output = []\n",
    "    \n",
    "    i = 0\n",
    "    for model in models_list:\n",
    "        key = model_keys[i]\n",
    "        params = hyper_a[key]\n",
    "        \n",
    "        i=i+1\n",
    "        print(model)\n",
    "        print(params)\n",
    "        print('----------------------------------------------------------------------------')\n",
    "        classifier = GridSearchCV(model,params,cv=5)\n",
    "        classifier.fit(X,y)\n",
    "        output.append({\n",
    "            \n",
    "            'model' : model,\n",
    "            'score':classifier.best_score_,\n",
    "            'hyperparameters':classifier.best_params_\n",
    "        })\n",
    "        output_dataframe = pd.DataFrame( output,columns = ['model','score','hyperparameters'])\n",
    "    return output_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6bc7764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(max_iter=10000)\n",
      "{'C': [1, 5, 10, 20]}\n",
      "----------------------------------------------------------------------------\n",
      "SVC()\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'C': [1, 5, 10, 20]}\n",
      "----------------------------------------------------------------------------\n",
      "KNeighborsClassifier()\n",
      "{'n_neighbors': [3, 5, 10]}\n",
      "----------------------------------------------------------------------------\n",
      "RandomForestClassifier(random_state=0)\n",
      "{'n_estimators': array([ 10,  20,  30,  40,  50,  60,  70,  80,  90, 100, 110, 120, 130,\n",
      "       140, 150, 160, 170, 180, 190, 200]), 'criterion': ['entropy', 'gini', 'log_loss'], 'max_features': array([1, 2, 3, 4, 5])}\n",
      "----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "500 fits failed out of a total of 1500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "500 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\kelvin\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\kelvin\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\kelvin\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\kelvin\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\kelvin\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\kelvin\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\kelvin\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.9125 0.9125 0.915  0.9175 0.9125 0.9175 0.9125 0.915  0.9175 0.915\n",
      " 0.9175 0.925  0.9225 0.9225 0.9225 0.92   0.92   0.92   0.9225 0.9225\n",
      " 0.93   0.935  0.9375 0.935  0.935  0.9325 0.9325 0.93   0.9325 0.935\n",
      " 0.9325 0.935  0.935  0.935  0.935  0.935  0.935  0.935  0.935  0.935\n",
      " 0.9275 0.9325 0.9275 0.93   0.9325 0.9325 0.9325 0.9325 0.9325 0.93\n",
      " 0.93   0.93   0.9325 0.93   0.9325 0.9325 0.9375 0.935  0.93   0.935\n",
      " 0.925  0.9275 0.93   0.9275 0.9325 0.9275 0.9275 0.925  0.9275 0.9275\n",
      " 0.925  0.925  0.925  0.925  0.9275 0.9275 0.9275 0.9275 0.9275 0.9275\n",
      " 0.9375 0.94   0.9325 0.9275 0.93   0.9275 0.9275 0.925  0.925  0.93\n",
      " 0.9275 0.9275 0.9275 0.925  0.925  0.925  0.9275 0.925  0.9275 0.925\n",
      " 0.905  0.9225 0.9225 0.9225 0.925  0.925  0.925  0.9275 0.92   0.925\n",
      " 0.925  0.92   0.92   0.92   0.92   0.925  0.9225 0.9225 0.925  0.9275\n",
      " 0.9275 0.9325 0.9275 0.93   0.9325 0.93   0.9325 0.9275 0.93   0.93\n",
      " 0.935  0.93   0.93   0.93   0.93   0.93   0.93   0.93   0.93   0.9275\n",
      " 0.9275 0.925  0.9325 0.935  0.9325 0.9325 0.9325 0.935  0.925  0.9275\n",
      " 0.9225 0.9225 0.925  0.9225 0.9275 0.93   0.93   0.9325 0.935  0.9325\n",
      " 0.93   0.925  0.925  0.9275 0.9275 0.925  0.9225 0.9225 0.925  0.9275\n",
      " 0.9225 0.925  0.9275 0.9275 0.925  0.925  0.925  0.925  0.9275 0.9275\n",
      " 0.9225 0.935  0.925  0.9275 0.9325 0.9325 0.9275 0.93   0.9275 0.9275\n",
      " 0.9225 0.925  0.9275 0.925  0.9275 0.9275 0.925  0.9275 0.9275 0.9275\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan    nan    nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(max_iter=10000)</td>\n",
       "      <td>0.9200</td>\n",
       "      <td>{'C': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.9225</td>\n",
       "      <td>{'C': 1, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.9075</td>\n",
       "      <td>{'n_neighbors': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier(random_state=0)</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 5, 'n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    model   score  \\\n",
       "0      LogisticRegression(max_iter=10000)  0.9200   \n",
       "1                                   SVC()  0.9225   \n",
       "2                  KNeighborsClassifier()  0.9075   \n",
       "3  RandomForestClassifier(random_state=0)  0.9400   \n",
       "\n",
       "                                     hyperparameters  \n",
       "0                                           {'C': 1}  \n",
       "1                       {'C': 1, 'kernel': 'linear'}  \n",
       "2                                {'n_neighbors': 10}  \n",
       "3  {'criterion': 'entropy', 'max_features': 5, 'n...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelSelection(models_list, model_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52f8f25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9d34bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(max_iter=10000)\n",
      "{'C': [1, 5, 10, 20]}\n",
      "----------------------------------------------------------------------------\n",
      "SVC()\n",
      "{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'], 'C': [1, 5, 10, 20]}\n",
      "----------------------------------------------------------------------------\n",
      "KNeighborsClassifier()\n",
      "{'n_neighbors': [3, 5, 10]}\n",
      "----------------------------------------------------------------------------\n",
      "RandomForestClassifier(random_state=0)\n",
      "{'n_estimators': array([ 10,  20,  30,  40,  50,  60,  70,  80,  90, 100, 110, 120, 130,\n",
      "       140, 150, 160, 170, 180, 190, 200]), 'criterion': ['entropy', 'gini', 'log_loss'], 'max_features': array([1, 2, 3, 4, 5])}\n",
      "----------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "500 fits failed out of a total of 1500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "500 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\kelvin\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\parallel.py\", line 1085, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\kelvin\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\parallel.py\", line 901, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\kelvin\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\parallel.py\", line 819, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\kelvin\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\kelvin\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\_parallel_backends.py\", line 597, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\kelvin\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\parallel.py\", line 288, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\kelvin\\AppData\\Roaming\\Python\\Python39\\site-packages\\joblib\\parallel.py\", line 288, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\Stats_software\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.9125 0.9125 0.915  0.9175 0.9125 0.9175 0.9125 0.915  0.9175 0.915\n",
      " 0.9175 0.925  0.9225 0.9225 0.9225 0.92   0.92   0.92   0.9225 0.9225\n",
      " 0.93   0.935  0.9375 0.935  0.935  0.9325 0.9325 0.93   0.9325 0.935\n",
      " 0.9325 0.935  0.935  0.935  0.935  0.935  0.935  0.935  0.935  0.935\n",
      " 0.9275 0.9325 0.9275 0.93   0.9325 0.9325 0.9325 0.9325 0.9325 0.93\n",
      " 0.93   0.93   0.9325 0.93   0.9325 0.9325 0.9375 0.935  0.93   0.935\n",
      " 0.925  0.9275 0.93   0.9275 0.9325 0.9275 0.9275 0.925  0.9275 0.9275\n",
      " 0.925  0.925  0.925  0.925  0.9275 0.9275 0.9275 0.9275 0.9275 0.9275\n",
      " 0.9375 0.94   0.9325 0.9275 0.93   0.9275 0.9275 0.925  0.925  0.93\n",
      " 0.9275 0.9275 0.9275 0.925  0.925  0.925  0.9275 0.925  0.9275 0.925\n",
      " 0.905  0.9225 0.9225 0.9225 0.925  0.925  0.925  0.9275 0.92   0.925\n",
      " 0.925  0.92   0.92   0.92   0.92   0.925  0.9225 0.9225 0.925  0.9275\n",
      " 0.9275 0.9325 0.9275 0.93   0.9325 0.93   0.9325 0.9275 0.93   0.93\n",
      " 0.935  0.93   0.93   0.93   0.93   0.93   0.93   0.93   0.93   0.9275\n",
      " 0.9275 0.925  0.9325 0.935  0.9325 0.9325 0.9325 0.935  0.925  0.9275\n",
      " 0.9225 0.9225 0.925  0.9225 0.9275 0.93   0.93   0.9325 0.935  0.9325\n",
      " 0.93   0.925  0.925  0.9275 0.9275 0.925  0.9225 0.9225 0.925  0.9275\n",
      " 0.9225 0.925  0.9275 0.9275 0.925  0.925  0.925  0.925  0.9275 0.9275\n",
      " 0.9225 0.935  0.925  0.9275 0.9325 0.9325 0.9275 0.93   0.9275 0.9275\n",
      " 0.9225 0.925  0.9275 0.925  0.9275 0.9275 0.925  0.9275 0.9275 0.9275\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan    nan    nan\n",
      "    nan    nan    nan    nan    nan    nan    nan    nan    nan    nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score</th>\n",
       "      <th>hyperparameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression(max_iter=10000)</td>\n",
       "      <td>0.9200</td>\n",
       "      <td>{'C': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.9225</td>\n",
       "      <td>{'C': 1, 'kernel': 'linear'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>0.9075</td>\n",
       "      <td>{'n_neighbors': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestClassifier(random_state=0)</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>{'criterion': 'entropy', 'max_features': 5, 'n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    model   score  \\\n",
       "0      LogisticRegression(max_iter=10000)  0.9200   \n",
       "1                                   SVC()  0.9225   \n",
       "2                  KNeighborsClassifier()  0.9075   \n",
       "3  RandomForestClassifier(random_state=0)  0.9400   \n",
       "\n",
       "                                     hyperparameters  \n",
       "0                                           {'C': 1}  \n",
       "1                       {'C': 1, 'kernel': 'linear'}  \n",
       "2                                {'n_neighbors': 10}  \n",
       "3  {'criterion': 'entropy', 'max_features': 5, 'n...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelSelection(models_list,model_hyperparameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
